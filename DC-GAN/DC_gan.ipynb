{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCsjx1ECd4h9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image,make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "z_dim = 100\n",
        "image_size = 28\n",
        "channels = 1\n",
        "epochs = 50\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"generated_images\",exist_ok = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5))\n",
        "])\n",
        "train_loader = torch.utils.data.DataLoader(datasets.MNIST(root = \"./data\",\n",
        "                              train=True,\n",
        "                              transform=transform,\n",
        "                              download=True),\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle=True)"
      ],
      "metadata": {
        "id": "wwjDPDk4lWFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,z_dim):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.ConvTranspose2d(z_dim,256,7,1,0,bias=False),  # 256 x 7 x 7\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(256,128,4,2,1,bias=False),    # 128 x 14 x 14\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(128,1,4,2,1,bias=False),    # 64 x 28 x 28\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def forward(self,z):\n",
        "    return self.net(z)"
      ],
      "metadata": {
        "id": "2aGhXTekniNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import Sigmoid\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(1,64,4,2,1,bias=False),  # 64 x 14 x 14\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Conv2d(64,128,4,2,1,bias=False),  # 128 x 7 x 7\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(128 * 7 * 7,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self,img):\n",
        "    return self.net(img)"
      ],
      "metadata": {
        "id": "dUcRmXs5r0G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(z_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(),lr=lr,betas = (beta1,0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(),lr = lr,betas= (beta1,0.999))"
      ],
      "metadata": {
        "id": "-S0RtbwDuMoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = torch.randn(64,z_dim,1,1).to(device)\n",
        "def generate_and_save_images(epoch):\n",
        "  generator.eval()\n",
        "  with torch.no_grad():\n",
        "    fake_images = generator(fixed_noise).detach().cpu()\n",
        "    fake_images = fake_images * 0.5 + 0.5\n",
        "    save_image(fake_images,f\"generated_images/sample_epoch_{epoch}.png\",nrow=8)\n",
        "  generator.train()"
      ],
      "metadata": {
        "id": "O5s52BNgu8IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "p = 1"
      ],
      "metadata": {
        "id": "TnVDsVtgwmbG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,epochs + 1):\n",
        "  for i,(real_images,_) in enumerate(train_loader):\n",
        "    batch_size_curr = real_images.shape[0]\n",
        "    real_images = real_images.to(device)\n",
        "    real_labels = torch.ones(batch_size_curr,1,device = device)\n",
        "    fake_labels = torch.zeros(batch_size_curr,1,device = device)\n",
        "\n",
        "    # Train Discriminator p - times\n",
        "    for _ in range(p):\n",
        "      noise = torch.randn(batch_size_curr,z_dim,1,1,device=device)\n",
        "      fake_images = generator(noise)\n",
        "      fake_loss = criterion(discriminator(fake_images.detach()),fake_labels)\n",
        "      real_loss = criterion(discriminator(real_images),real_labels)\n",
        "\n",
        "      total_loss = real_loss + fake_loss\n",
        "      optimizer_D.zero_grad()\n",
        "      total_loss.backward()\n",
        "      optimizer_D.step()\n",
        "\n",
        "     # Train Generator k - times\n",
        "    for _ in range(k):\n",
        "      noise = torch.randn(batch_size_curr,z_dim,1,1,device=device)\n",
        "      fake_images = generator(noise)\n",
        "      generator_loss = criterion(discriminator(fake_images),real_labels)  # Fool D -> labels as Real\n",
        "      optimizer_G.zero_grad()\n",
        "      generator_loss.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "    if i%200 == 0:\n",
        "      print(f\"Epoch [{epoch}/{epochs}] | Batch [{i}/{len(train_loader)}] | \"\n",
        "            f\"D_Loss: {total_loss.item():.4f} | G_Loss :{generator_loss.item():.4f}\" )\n",
        "  generator.eval()\n",
        "  generate_and_save_images(epoch)\n"
      ],
      "metadata": {
        "id": "Nxs2MjoXwtBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}