{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CREv5VJNTWwY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "uU370nedZhKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5,))\n",
        "])\n",
        "\n",
        "training_data = torchvision.datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train = True,\n",
        "    transform=transform,\n",
        "    download = True\n",
        ")\n",
        "train_loader = DataLoader(training_data,batch_size = 128, shuffle = True)"
      ],
      "metadata": {
        "id": "GGP6fWcCYbTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,z_dim,img_dim):\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        nn.Linear(z_dim,256),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(256,1024),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(1024,img_dim),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def forward(self,z):\n",
        "    return self.gen(z)"
      ],
      "metadata": {
        "id": "vqEDBmZzvoSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,img_dim):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        nn.Linear(img_dim,512),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "        nn.Linear(512,256),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "        nn.Linear(256,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self,img):\n",
        "    return self.disc(img)\n"
      ],
      "metadata": {
        "id": "BYG4-4M0oiVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_dim = 100\n",
        "img_dim = 28 * 28\n",
        "\n",
        "generator = Generator(noise_dim,img_dim).to(device)\n",
        "discriminator = Discriminator(img_dim).to(device)\n",
        "\n",
        "g_optimizer = optim.Adam(generator.parameters(),lr=0.0002)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(),lr=0.0002)\n",
        "\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "ThMrQTcBoiXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = generator.to(device)\n",
        "discriminator = discriminator.to(device)"
      ],
      "metadata": {
        "id": "37fCRzWoCVC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_generated_images(epoch,generator,fixed_noise):\n",
        "  generator.eval()\n",
        "  with torch.no_grad():\n",
        "    fake_imgs = generator(fixed_noise).reshape(-1,1,28,28)\n",
        "    fake_imgs = fake_imgs * 0.5 + 0.5\n",
        "  grid = torchvision.utils.make_grid(fake_imgs,nrow=8)\n",
        "  plt.figure(figsize = (8,8))\n",
        "  plt.imshow(grid.permute(1,2,0).cpu().numpy())\n",
        "  plt.title(f'Generated Images at epoch {epoch}')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  generator.train()\n"
      ],
      "metadata": {
        "id": "_hnkJaQixXaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FTlAFWf5DMSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(train_loader,num_epochs,num_gen=1,num_disc=1):\n",
        "  fixed_noise = torch.randn(64,noise_dim).to(device)\n",
        "  for epoch in range(num_epochs):\n",
        "    for batch_idx,(real,_) in enumerate(train_loader):\n",
        "      batch_size = real.shape[0]\n",
        "      real = real.view(batch_size,-1).to(device)\n",
        "      real_labels = torch.ones(batch_size,1).to(device)\n",
        "      fake_labels = torch.zeros(batch_size,1).to(device)\n",
        "\n",
        "\n",
        "      for _ in range(num_disc):\n",
        "        #  1. Train Discriminator\n",
        "        outputs = discriminator(real)\n",
        "        d_real_loss = criterion(outputs,real_labels)\n",
        "        real_score = outputs\n",
        "\n",
        "        z = torch.randn(batch_size,noise_dim).to(device)\n",
        "        fake_imgs = generator(z)\n",
        "        outputs = discriminator(fake_imgs.detach())\n",
        "        d_fake_loss = criterion(outputs,fake_labels)\n",
        "        fake_score = outputs\n",
        "\n",
        "\n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "        discriminator.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "      for _ in range(num_gen):\n",
        "        #  2. Train Generator\n",
        "        z = torch.randn(batch_size,noise_dim).to(device)\n",
        "        fake_imgs = generator(z)\n",
        "        outputs = discriminator(fake_imgs)\n",
        "\n",
        "        g_loss = criterion(outputs,real_labels)  # Think why real_labels are being used ??\n",
        "        generator.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "\n",
        "    if (epoch + 1)%10 == 0:\n",
        "      print(f\"Epoch : [{epoch+1}/{num_epochs}] , D_Loss : {d_loss.item():.4f}, G_Loss : {g_loss.item():.4f}\")\n",
        "      show_generated_images(epoch+1,generator,fixed_noise)"
      ],
      "metadata": {
        "id": "uPDg5efkzOgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gan(train_loader,num_epochs=50,num_gen=1,num_disc=1)"
      ],
      "metadata": {
        "id": "5u7dKma6zT6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Saturating vs Non-Saturating GAN Losses and Their Gradients\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Discriminator output range\n",
        "d = np.linspace(1e-5, 1 - 1e-5, 500)\n",
        "\n",
        "# Loss functions\n",
        "saturating_loss = np.log(1 - d)                 # Generator minimax loss\n",
        "non_saturating_loss = -np.log(d)                # Non-saturating loss\n",
        "\n",
        "# Gradients (magnitude)\n",
        "grad_saturating = 1 / (1 - d)\n",
        "grad_non_saturating = 1 / d\n",
        "\n",
        "# ---- Plot 1: Loss curves ----\n",
        "plt.figure()\n",
        "plt.plot(d, saturating_loss, label=\"Saturating Loss: log(1 - D(G(z)))\")\n",
        "plt.plot(d, non_saturating_loss, label=\"Non-Saturating Loss: -log(D(G(z)))\")\n",
        "plt.xlabel(\"D(G(z))\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Generator Loss Functions\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ---- Plot 2: Gradient magnitude curves ----\n",
        "plt.figure()\n",
        "plt.plot(d, grad_saturating, label=\"Gradient (Saturating Loss)\")\n",
        "plt.plot(d, grad_non_saturating, label=\"Gradient (Non-Saturating Loss)\")\n",
        "plt.xlabel(\"D(G(z))\")\n",
        "plt.ylabel(\"Gradient Magnitude\")\n",
        "plt.title(\"Gradient Behavior of Generator Losses\")\n",
        "plt.ylim(0, 20)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "VKnWiSYJ0QPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct tangent visualization for Saturating vs Non-Saturating GAN losses\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Discriminator output range\n",
        "d = np.linspace(1e-5, 1 - 1e-5, 500)\n",
        "\n",
        "# Loss functions\n",
        "saturating_loss = np.log(1 - d)          # minimax loss\n",
        "non_saturating_loss = -np.log(d)         # non-saturating loss\n",
        "\n",
        "# Point where discriminator is very confident\n",
        "d0 = 0.05\n",
        "\n",
        "# Loss values at d0\n",
        "loss0_sat = np.log(1 - d0)\n",
        "loss0_ns = -np.log(d0)\n",
        "\n",
        "# Correct derivatives (slopes)\n",
        "grad_sat = -1 / (1 - d0)   # derivative of log(1 - x)\n",
        "grad_ns = -1 / d0          # derivative of -log(x)\n",
        "\n",
        "# Tangent x-range (local region)\n",
        "tangent_x = np.linspace(d0 - 0.03, d0 + 0.03, 100)\n",
        "\n",
        "# Tangent lines\n",
        "tangent_sat = loss0_sat + grad_sat * (tangent_x - d0)\n",
        "tangent_ns = loss0_ns + grad_ns * (tangent_x - d0)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(d, saturating_loss, label=\"Saturating Loss\", linewidth=2)\n",
        "plt.plot(d, non_saturating_loss, label=\"Non-Saturating Loss\", linewidth=2)\n",
        "\n",
        "plt.plot(tangent_x, tangent_sat, \"--\", label=\"Tangent (Saturating)\", linewidth=2)\n",
        "plt.plot(tangent_x, tangent_ns, \"--\", label=\"Tangent (Non-Saturating)\", linewidth=2)\n",
        "\n",
        "plt.scatter([d0], [loss0_sat], s=60)\n",
        "plt.scatter([d0], [loss0_ns], s=60)\n",
        "\n",
        "plt.xlabel(\"D(G(z))\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Slope (Gradient) Comparison at Low D(G(z))\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-fwFRCaa-CUo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}