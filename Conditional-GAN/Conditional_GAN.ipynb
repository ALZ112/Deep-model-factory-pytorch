{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eZGiGpNWm8EJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image,make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "z_dim = 100\n",
        "emb_dim = 10\n",
        "image_size = 28\n",
        "channels = 1\n",
        "epochs = 50\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"generated_images\",exist_ok = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5))\n",
        "])\n",
        "train_loader = torch.utils.data.DataLoader(datasets.MNIST(root = \"./data\",\n",
        "                              train=True,\n",
        "                              transform=transform,\n",
        "                              download=True),\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle=True)"
      ],
      "metadata": {
        "id": "dG2OYyrSpl0i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,z_dim,emb_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(10,emb_dim)\n",
        "    self.net = nn.Sequential(\n",
        "        nn.ConvTranspose2d(z_dim + emb_dim,256,7,1,0,bias=False),  # 256 x 7 x 7\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(256,128,4,2,1,bias=False),    # 128 x 14 x 14\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(128,1,4,2,1,bias=False),    # 64 x 28 x 28\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def forward(self,z,ip_num):\n",
        "    emb = self.embedding(ip_num).squeeze(1).unsqueeze(2).unsqueeze(3)\n",
        "    z = torch.cat([z,emb],dim=1)\n",
        "    return self.net(z)"
      ],
      "metadata": {
        "id": "ep2YpJD_pnnt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import Sigmoid\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(1,64,4,2,1,bias=False),  # 64 x 14 x 14\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Conv2d(64,128,4,2,1,bias=False),  # 128 x 7 x 7\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(128 * 7 * 7,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self,img):\n",
        "    return self.net(img)\n",
        "\n",
        "class ProjectionDiscriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(1,64,4,2,1,bias=False),  # 64 x 14 x 14\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Conv2d(64,128,4,2,1,bias=False), # 128 x 7 x 7,\n",
        "        nn.LeakyReLU(0.2,True),\n",
        "        nn.Flatten()\n",
        "    )\n",
        "    self.linear = nn.Linear(128 * 7 * 7 , 1)\n",
        "    self.embedding = nn.Embedding(10,emb_dim)\n",
        "    self.act = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,img,labels):\n",
        "    h = self.conv(img)   # b x (128x7x7)\n",
        "    out = self.linear(h) # b x 1\n",
        "    emb = self.embedding(labels).squeeze(1) # b x c\n",
        "    out = out + torch.sum(h[:,:emb.shape[1]] * emb,dim=1,keepdim=True)  # b x 1\n",
        "    return self.act(out)\n"
      ],
      "metadata": {
        "id": "4qQUQyTkpqBI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(z_dim,emb_dim).to(device)\n",
        "discriminator = ProjectionDiscriminator().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(),lr=lr,betas = (beta1,0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(),lr = lr,betas= (beta1,0.999))"
      ],
      "metadata": {
        "id": "ahlzQD_TpreS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fixed_noise = torch.randn(64,z_dim,1,1).to(device)\n",
        "# fixed_labels = torch.randint(0,10,(64,1)).to(device)\n",
        "# def generate_and_save_images(epoch):\n",
        "#   generator.eval()\n",
        "#   with torch.no_grad():\n",
        "#     fake_images = generator(fixed_noise,fixed_labels).detach().cpu()\n",
        "#     fake_images = fake_images * 0.5 + 0.5\n",
        "#     save_image(fake_images,f\"generated_images/sample_epoch_{epoch}.png\",nrow=8)\n",
        "#   generator.train()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
        "fixed_labels = torch.randint(0, 10, (64,), device=device)\n",
        "\n",
        "def generate_and_save_images(epoch):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        fake_images = generator(fixed_noise, fixed_labels)   # (64, 1, 28, 28)\n",
        "        fake_images = fake_images * 0.5 + 0.5                # denormalize\n",
        "        fake_images = fake_images.cpu()\n",
        "\n",
        "    grid = torchvision.utils.make_grid(fake_images, nrow=8, padding=2)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(grid.permute(1, 2, 0).squeeze(), cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Epoch {epoch}\")\n",
        "\n",
        "    # ---- Add labels ----\n",
        "    img_size = fake_images.size(2) + 2  # image + padding\n",
        "    for idx, label in enumerate(fixed_labels.cpu()):\n",
        "        row = idx // 8\n",
        "        col = idx % 8\n",
        "        x = col * img_size + 2\n",
        "        y = row * img_size + 12\n",
        "        plt.text(x, y, str(label.item()), color=\"red\", fontsize=10)\n",
        "\n",
        "    plt.savefig(f\"generated_images/sample_epoch_{epoch}.png\")\n",
        "    plt.show()\n",
        "\n",
        "    generator.train()\n"
      ],
      "metadata": {
        "id": "mJ8MtLe5ps1C"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 1\n",
        "p = 1"
      ],
      "metadata": {
        "id": "4PHECAWapulg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,epochs + 1):\n",
        "  for i,(real_images,real_labels_int) in enumerate(train_loader):\n",
        "    batch_size_curr = real_images.shape[0]\n",
        "    real_images = real_images.to(device)\n",
        "    real_labels = torch.ones(batch_size_curr,1,device = device)\n",
        "    fake_labels = torch.zeros(batch_size_curr,1,device = device)\n",
        "\n",
        "    # Train Discriminator p - times\n",
        "    for _ in range(p):\n",
        "      noise = torch.randn(batch_size_curr,z_dim,1,1,device=device)\n",
        "      fake_labels_int = torch.randint(0,10,(batch_size_curr,1),device=device)\n",
        "      fake_images = generator(noise,fake_labels_int)\n",
        "      fake_loss = criterion(discriminator(fake_images.detach(),fake_labels_int),fake_labels)\n",
        "      real_loss = criterion(discriminator(real_images,real_labels_int),real_labels)\n",
        "\n",
        "      total_loss = real_loss + fake_loss\n",
        "      optimizer_D.zero_grad()\n",
        "      total_loss.backward()\n",
        "      optimizer_D.step()\n",
        "\n",
        "     # Train Generator k - times\n",
        "    for _ in range(k):\n",
        "      noise = torch.randn(batch_size_curr,z_dim,1,1,device=device)\n",
        "      fake_labels_int = torch.randint(0,10,(batch_size_curr,1),device=device)\n",
        "      fake_images = generator(noise,fake_labels_int)\n",
        "      generator_loss = criterion(discriminator(fake_images,fake_labels_int),real_labels)  # Fool D -> labels as Real\n",
        "      optimizer_G.zero_grad()\n",
        "      generator_loss.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "    if i%200 == 0:\n",
        "      print(f\"Epoch [{epoch}/{epochs}] | Batch [{i}/{len(train_loader)}] | \"\n",
        "            f\"D_Loss: {total_loss.item():.4f} | G_Loss :{generator_loss.item():.4f}\" )\n",
        "  generator.eval()\n",
        "  generate_and_save_images(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yz9Oq-EpyID",
        "outputId": "0adbe155-4d40-4287-ed14-5a338147c6a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] | Batch [0/469] | D_Loss: 1.3447 | G_Loss :0.7276\n"
          ]
        }
      ]
    }
  ]
}