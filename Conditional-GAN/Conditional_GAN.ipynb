{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image,make_grid\nimport matplotlib.pyplot as plt\nimport os\n\n# Hyperparameters\nbatch_size = 128\nz_dim = 128\nemb_dim = 128\nimage_size = 28\nchannels = 1\nepochs = 50\nlr = 0.0002\nbeta1 = 0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nos.makedirs(\"generated_images\",exist_ok = True)\n","metadata":{"id":"eZGiGpNWm8EJ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,),(0.5))\n])\ntrain_loader = torch.utils.data.DataLoader(datasets.MNIST(root = \"./data\",\n                              train=True,\n                              transform=transform,\n                              download=True),\n                                           batch_size = batch_size,\n                                           shuffle=True)","metadata":{"id":"dG2OYyrSpl0i","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Generator(nn.Module):\n  def __init__(self,z_dim,emb_dim):\n    super().__init__()\n    self.embedding = nn.Embedding(10,emb_dim)\n    self.net = nn.Sequential(\n        nn.ConvTranspose2d(z_dim + emb_dim,256,7,1,0,bias=False),  # 256 x 7 x 7\n        nn.BatchNorm2d(256),\n        nn.ReLU(True),\n        nn.ConvTranspose2d(256,128,4,2,1,bias=False),    # 128 x 14 x 14\n        nn.BatchNorm2d(128),\n        nn.ReLU(True),\n        nn.ConvTranspose2d(128,1,4,2,1,bias=False),    # 64 x 28 x 28\n        nn.Tanh()\n    )\n  def forward(self,z,ip_num):\n    emb = self.embedding(ip_num).squeeze(1).unsqueeze(2).unsqueeze(3)\n    z = torch.cat([z,emb],dim=1)\n    return self.net(z)\n\n\nclass GeneratorImproved(nn.Module):\n  def __init__(self,z_dim,emb_dim):\n    super().__init__()\n    self.embedding = nn.Embedding(10,emb_dim)\n    self.net = nn.Sequential(\n        nn.ConvTranspose2d(z_dim + emb_dim,256,7,1,0,bias=False),  # 256 x 7 x 7\n        nn.BatchNorm2d(256),\n        nn.ReLU(True),\n        nn.ConvTranspose2d(256,128,4,2,1,bias=False),    # 128 x 14 x 14\n        nn.BatchNorm2d(128),\n        nn.ReLU(True),\n        nn.ConvTranspose2d(128,1,4,2,1,bias=False),    # 64 x 28 x 28\n        nn.Tanh()\n    )\n    self.gamma = 1\n    self.beta = 0\n  def forward(self,z,ip_num):\n    emb = self.embedding(ip_num).squeeze(1).unsqueeze(2).unsqueeze(3)\n    z = torch.cat([z,emb],dim=1)\n    return self.net(z)","metadata":{"id":"ep2YpJD_pnnt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.nn.modules.activation import Sigmoid\nclass Discriminator(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.net = nn.Sequential(\n        nn.Conv2d(1,64,4,2,1,bias=False),  # 64 x 14 x 14\n        nn.LeakyReLU(0.2,True),\n        nn.Conv2d(64,128,4,2,1,bias=False),  # 128 x 7 x 7\n        nn.BatchNorm2d(128),\n        nn.LeakyReLU(0.2,True),\n        nn.Flatten(),\n        nn.Linear(128 * 7 * 7,1),\n        nn.Sigmoid()\n    )\n  def forward(self,img):\n    return self.net(img)\n\nclass ProjectionDiscriminator(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.conv = nn.Sequential(\n        nn.Conv2d(1,64,4,2,1,bias=False),  # 64 x 14 x 14\n        nn.LeakyReLU(0.2,True),\n        nn.Conv2d(64,128,4,2,1,bias=False), # 128 x 7 x 7,\n        nn.LeakyReLU(0.2,True),\n        nn.Flatten()\n    )\n    self.linear = nn.Linear(128 * 7 * 7 , 1)\n    self.embedding = nn.Embedding(10,emb_dim)\n    self.act = nn.Sigmoid()\n\n  def forward(self,img,labels):\n    h = self.conv(img)   # b x (128x7x7)\n    out = self.linear(h) # b x 1\n    emb = self.embedding(labels).squeeze(1) # b x c\n    out = out + torch.sum(h[:,:emb.shape[1]] * emb,dim=1,keepdim=True)  # b x 1\n    return self.act(out)\n\nclass ProjectionDiscriminatorImproved(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.conv = nn.Sequential(\n        nn.Conv2d(1,64,4,2,1,bias=False),  # 64 x 14 x 14\n        nn.LeakyReLU(0.2,True),\n        nn.Conv2d(64,128,4,2,1,bias=False), # 128 x 7 x 7,\n        nn.LeakyReLU(0.2,True),\n        # nn.Flatten()\n    )\n    self.flat = nn.Flatten()\n    self.linear = nn.Linear(128 * 7 * 7 , 1)\n    self.embedding = nn.Embedding(10,emb_dim)\n    self.act = nn.Sigmoid()\n\n  def forward(self,img,labels):\n    h = self.conv(img)   # b x (128x7x7)\n    h_pool = torch.sum(h, dim=(2,3))  # (B, 128)\n    h = self.flat(h)\n    out = self.linear(h) # b x 1\n    emb = self.embedding(labels).squeeze(1) # b x c\n    out = out + torch.sum(h_pool * emb,dim=1,keepdim=True)  # b x 1\n    return out\n    # return self.act(out)\n","metadata":{"id":"4qQUQyTkpqBI","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# generator = Generator(z_dim,emb_dim).to(device)\n# discriminator = ProjectionDiscriminator().to(device)\n\ngenerator = GeneratorImproved(z_dim,emb_dim).to(device)\ndiscriminator = ProjectionDiscriminatorImproved().to(device)\n\n# criterion = nn.BCELoss()\ncriterion = nn.BCEWithLogitsLoss()\n\noptimizer_G = optim.Adam(generator.parameters(),lr=lr,betas = (beta1,0.999))\noptimizer_D = optim.Adam(discriminator.parameters(),lr = lr,betas= (beta1,0.999))","metadata":{"id":"ahlzQD_TpreS","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torchvision\n\n\n\ndef generate_and_save_images(epoch):\n    generator.eval()\n\n    # ---- Create fixed noise and labels ----\n    num_per_class = 10\n    num_iterations = 3\n    \n    labels = torch.tensor(\n        [_ for i in range(num_iterations) for _ in range(num_per_class)],\n        device=device\n    )  # (30,)\n\n    noise = torch.randn(num_iterations * num_per_class, z_dim, 1, 1, device=device)\n    \n    with torch.no_grad():\n        fake_images = generator(noise, labels.flatten())\n        fake_images = fake_images * 0.5 + 0.5\n        fake_images = fake_images.cpu()\n\n    # ---- Make grid ----\n    grid = torchvision.utils.make_grid(\n        fake_images, nrow=10, padding=2\n    )\n\n    plt.figure(figsize=(12, 4))\n    plt.imshow(grid.permute(1, 2, 0).squeeze(), cmap=\"gray\")\n    plt.axis(\"off\")\n    plt.title(f\"Epoch {epoch}\")\n\n    # ---- Add labels ----\n    img_size = fake_images.size(2) + 2  # image + padding\n    for idx, label in enumerate(labels.cpu()):\n        row = idx // 10\n        col = idx % 10\n        x = col * img_size + 2\n        y = row * img_size + 12\n        plt.text(x, y, str(label.item()), color=\"red\", fontsize=12)\n\n    plt.savefig(f\"generated_images/sample_epoch_{epoch}.png\")\n    plt.show()\n\n    generator.train()\n","metadata":{"id":"mJ8MtLe5ps1C","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"k = 3\np = 1","metadata":{"id":"4PHECAWapulg","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(1,epochs + 1):\n  for i,(real_images,real_labels_int) in enumerate(train_loader):\n    batch_size_curr = real_images.shape[0]\n    real_images = real_images.to(device)\n    real_labels = torch.ones(batch_size_curr,1,device = device)\n    fake_labels = torch.zeros(batch_size_curr,1,device = device)\n\n    # Train Discriminator p - times\n    for _ in range(p):\n      noise = torch.randn(batch_size_curr,z_dim,1,1,device=device)\n      fake_labels_int = torch.randint(0,10,(batch_size_curr,1),device=device)\n      fake_images = generator(noise,fake_labels_int)\n      fake_loss = criterion(discriminator(fake_images.detach(),fake_labels_int),fake_labels)\n      real_loss = criterion(discriminator(real_images,real_labels_int.to(device)),real_labels)\n\n      total_loss = real_loss + fake_loss\n      optimizer_D.zero_grad()\n      total_loss.backward()\n      optimizer_D.step()\n\n     # Train Generator k - times\n    for _ in range(k):\n      noise = torch.randn(batch_size_curr,z_dim,1,1,device=device)\n      fake_labels_int = torch.randint(0,10,(batch_size_curr,1),device=device)\n      fake_images = generator(noise,fake_labels_int)\n      generator_loss = criterion(discriminator(fake_images,fake_labels_int),real_labels)  # Fool D -> labels as Real\n      optimizer_G.zero_grad()\n      generator_loss.backward()\n      optimizer_G.step()\n\n    if i%200 == 0:\n      print(f\"Epoch [{epoch}/{epochs}] | Batch [{i}/{len(train_loader)}] | \"\n            f\"D_Loss: {total_loss.item():.4f} | G_Loss :{generator_loss.item():.4f}\" )\n  generator.eval()\n  generate_and_save_images(epoch)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yz9Oq-EpyID","outputId":"0adbe155-4d40-4287-ed14-5a338147c6a2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}